import os
import csv
import requests
from bs4 import BeautifulSoup
import time
import random
import pandas as pd
import numpy as np
import datetime
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.model_selection import cross_val_score  # Added the import for cross-validation
import matplotlib.pyplot as plt

# Function to display colored text in the terminal
def print_colored(text, color):
    # Mapping for terminal color codes
    colors = {
        "red": "\033[91m",
        "green": "\033[92m",
        "yellow": "\033[93m",
        "blue": "\033[94m",
        "orange": "\033[33m",
        "reset": "\033[0m"
    }
    print(f"{colors.get(color, colors['reset'])}{text}{colors['reset']}")

# List of User-Agent strings for rotation
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36",
    "Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15A372 Safari/604.1"
]

# Function to select random headers
def get_random_headers():
    headers = {
        "User-Agent": random.choice(USER_AGENTS),
        "Referer": f"https://www.google.com/search?q={random.randint(1000,9999)}",  # Adds a random query string to the referer
    }
    return headers

# Function to scrape prices and more info from TCGPlayer
def scrape_tcgplayer_prices(card_name):
    search_url = f"https://www.tcgplayer.com/search/all/product?q={card_name.replace(' ', '%20')}&random={random.randint(1000,9999)}"
    headers = get_random_headers()

    try:
        response = requests.get(search_url, headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')

        # Find price elements
        price_tags = soup.find_all('span', class_='price-point__data')

        # Find card condition elements (update the class based on the website's HTML structure)
        condition_tags = soup.find_all('span', class_='product__condition')  # Example class, adjust it

        # Find seller elements (update the class based on the website's HTML structure)
        seller_tags = soup.find_all('span', class_='seller-name')  # Example class, adjust it

        # Extract information
        prices = [float(tag.text.replace('$', '').strip()) for tag in price_tags]
        conditions = [tag.text.strip() for tag in condition_tags]
        sellers = [tag.text.strip() for tag in seller_tags]

        # Combine the data into a list of dictionaries
        card_data = []
        for i in range(min(len(prices), len(conditions), len(sellers))):
            card_data.append({
                "price": prices[i],
                "condition": conditions[i],
                "seller": sellers[i]
            })

        return card_data if card_data else []
    except Exception:
        print_colored("Unable to fetch prices from TCGPlayer.", "red")
        return []

# Function to scrape prices from CardMarket
def scrape_cardmarket_prices(card_name):
    search_url = f"https://www.cardmarket.com/en/Pokemon/Products/Search?searchString={card_name.replace(' ', '+')}&random={random.randint(1000,9999)}"
    headers = get_random_headers()

    try:
        response = requests.get(search_url, headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        price_tags = soup.find_all('div', class_='price-container')
        prices = []
        for tag in price_tags:
            price_text = tag.text.replace('€', '').replace(',', '.').strip()
            try:
                price = float(price_text)
                prices.append(price)
            except ValueError:
                continue
        return prices if prices else []
    except Exception:
        print_colored("Unable to fetch prices from CardMarket.", "red")
        return []

# Function to make parallel requests and use default prices if none are found
def get_prices_in_parallel(card_name):
    all_prices = []

    sources = [("TCGPlayer", scrape_tcgplayer_prices),
               ("eBay", scrape_ebay_prices),
               ("CardMarket", scrape_cardmarket_prices)]
    random.shuffle(sources)

    for source, scraper in sources:
        try:
            prices = scraper(card_name)
            if prices:
                all_prices.extend(prices)
                print_colored(f"Prices from {source}: {prices}", "green")
            else:
                print_colored(f"No prices found from {source}.", "orange")
        except Exception as e:
            print_colored(f"Unable to fetch prices from {source}. Error: {e}", "red")

        time.sleep(random.uniform(1, 2))  # Random sleep to avoid rate-limiting

    return all_prices

# Function to calculate the average price
def average_price(prices):
    return sum(prices) / len(prices) if prices else 0

# Function to predict future prices using polynomial regression
def predict_prices_polynomial(historical_data):
    df = pd.DataFrame(historical_data)
    df['Date'] = pd.to_datetime(df['Date'])
    df['DateOrdinal'] = df['Date'].map(datetime.datetime.toordinal)

    # Features and target
    X = df[['DateOrdinal']]  # Dates
    y = df['Price']  # Prices

    # Apply polynomial regression
    poly = PolynomialFeatures(degree=3)
    X_poly = poly.fit_transform(X)

    model = LinearRegression()
    model.fit(X_poly, y)

    # Predict for the next 7 days
    future_dates = pd.date_range(start=df['Date'].max() + pd.Timedelta(days=1), periods=7)
    future_dates_ordinal = np.array([date.toordinal() for date in future_dates]).reshape(-1, 1)
    future_dates_poly = poly.transform(future_dates_ordinal)
    predicted_prices = model.predict(future_dates_poly)

    return future_dates, predicted_prices

# Function to plot price trends and predictions
def plot_prices(historical_data, future_dates, predicted_prices):
    df = pd.DataFrame(historical_data)
    df['Date'] = pd.to_datetime(df['Date'])

    plt.figure(figsize=(10, 5))
    plt.plot(df['Date'], df['Price'], label='Historical Prices', color='blue')
    plt.plot(future_dates, predicted_prices, label='Predicted Prices', linestyle='--', color='green')
    plt.xlabel('Date')
    plt.ylabel('Price (USD)')
    plt.title('Pokémon Card Price Prediction')
    plt.legend()
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

# Function to store historical data
def store_data(historical_data, card_name, avg_price, filename):
    today = datetime.datetime.today().strftime('%Y-%m-%d')
    historical_data.append({"Date": today, "Price": avg_price})

    # Save the updated data back to the CSV file
    with open(filename, 'w', newline='') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=["Date", "Price"])
        writer.writeheader()
        writer.writerows(historical_data)

# Function to load historical data from a CSV file
def load_historical_data(filename):
    if os.path.exists(filename):
        with open(filename, 'r') as csvfile:
            reader = csv.DictReader(csvfile)
            return list(reader)
    else:
        return []

# Main function to get prices, predict future prices, and notify user
def get_card_prices(card_name, filename="historical_data.csv"):
    # Reload historical data to ensure it's always updated in each loop iteration
    historical_data = load_historical_data(filename)

    all_prices = get_prices_in_parallel(card_name)
    avg_price = average_price(all_prices)

    if avg_price and len(set(all_prices)) > 1:  # Ensure it's not just random prices
        store_data(historical_data, card_name, avg_price, filename)
        print_colored(f"Average price for {card_name}: ${avg_price:.2f}", "blue")
    else:
        print_colored(f"No new credible prices. Showing historical data.", "orange")

    # Predict future prices using polynomial regression
    future_dates, predicted_prices = predict_prices_polynomial(historical_data)

    # Plot historical and predicted prices
    plot_prices(historical_data, future_dates, predicted_prices)

# Main program
def main():
    card_name = input("Enter the Pokémon card name: ")

    while True:
        get_card_prices(card_name)

        # Ask user whether to continue or stop
        should_continue = input("Do you want to continue checking prices? (y/n): ")
        if should_continue.lower() != 'y':
            print("Stopping price checks.")
            break

        time.sleep(3600)  # Wait for 1 hour before checking again

if __name__ == "__main__":
    main()
